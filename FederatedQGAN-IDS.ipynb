{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztIsgQIrtvW3"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install qiskit torch scikit-learn pandas numpy matplotlib jupyter qiskit-machine-learning scipy qiskit-algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lt-pu9NqtvW4"
   },
   "outputs": [],
   "source": [
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from qiskit.circuit.library import EfficientSU2, RealAmplitudes, ZZFeatureMap\n",
    "from qiskit.circuit import QuantumCircuit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.stats import entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eab4eYrAq9_4"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./KDDTrain+.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot'\n",
    ",'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations'\n",
    ",'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate'\n",
    ",'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'\n",
    ",'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate'\n",
    ",'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','outcome','level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe().style.background_gradient(cmap='Blues').set_properties(**{'font-family':'Segoe UI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset['outcome'] == \"normal\", \"outcome\"] = 'normal'\n",
    "dataset.loc[dataset['outcome'] != 'normal', \"outcome\"] = 'attack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot(df, cols_list, rows, cols):\n",
    "    fig, axes = plt.subplots(rows, cols)\n",
    "    for ax, col in zip(axes.ravel(), cols_list):\n",
    "        df[col].value_counts().plot(ax=ax, kind='pie', figsize=(15, 15), fontsize=10, autopct='%1.0f%%')\n",
    "        ax.set_title(str(col), fontsize = 12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot(dataset, ['protocol_type', 'outcome'], 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def Scaling(df_num, cols):\n",
    "    std_scaler = RobustScaler()\n",
    "    std_scaler_temp = std_scaler.fit_transform(df_num)\n",
    "    std_df = pd.DataFrame(std_scaler_temp, columns =cols)\n",
    "    return std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['is_host_login','protocol_type','service','flag','land', 'logged_in','is_guest_login', 'level', 'outcome']\n",
    "def preprocess(dataframe):\n",
    "    df_num = dataframe.drop(cat_cols, axis=1)\n",
    "    num_cols = df_num.columns\n",
    "    scaled_df = Scaling(df_num, num_cols)\n",
    "    \n",
    "    dataframe.drop(labels=num_cols, axis=\"columns\", inplace=True)\n",
    "    dataframe[num_cols] = scaled_df[num_cols]\n",
    "    \n",
    "    dataframe = pd.get_dummies(dataframe, columns = ['protocol_type', 'service', 'flag'])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocess(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['outcome']).values\n",
    "\n",
    "y = dataset['outcome'].values\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "ncomp=4\n",
    "\n",
    "# Apply PCA to the dataset\n",
    "pca = PCA(n_components=ncomp)  # Set the number of components to 10\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca = scaler.fit_transform(X_pca)\n",
    "\n",
    "# Print the explained variance ratio to see how much variance is captured by each component\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Convert the PCA result to a DataFrame for better visualization\n",
    "pca_df = pd.DataFrame(data=X_pca, columns=[f'Principal Component {i+1}' for i in range(ncomp)])\n",
    "pca_df['Outcome'] = y\n",
    "\n",
    "# Display the first few rows of the PCA result\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_dataT = X[y == 'attack']\n",
    "#benign_data_testT = X[y == 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_dataT = X[y == 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=8000\n",
    "test_size=2000\n",
    "n_device=4\n",
    "\n",
    "\n",
    "outlier_data = outlier_dataT[:test_size]\n",
    "#outlier_data2 = outlier_dataT[500:1000]\n",
    "benign_data_test = benign_dataT[:test_size]\n",
    "#benign_data_test2 = benign_dataT[500:1000]\n",
    "\n",
    "outlier_tensor = torch.tensor(outlier_data, dtype=torch.float32)\n",
    "benign_tensor = torch.tensor(benign_data_test, dtype=torch.float32)\n",
    "\n",
    "#outlier_tensor2 = torch.tensor(outlier_data2, dtype=torch.float32)\n",
    "#benign_tensor2 = torch.tensor(benign_data_test2, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_data = benign_dataT[test_size:train_size+test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozRuluwStvW5"
   },
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "algorithm_globals.random_seed = 123456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcda45KrtvW5"
   },
   "outputs": [],
   "source": [
    "# Define number of qubits based on the number of features in your data\n",
    "num_features = benign_data.shape[1]\n",
    "print(num_features)\n",
    "num_qubits = num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHFTOKYstvW5"
   },
   "outputs": [],
   "source": [
    "qc = QuantumCircuit(num_qubits)\n",
    "qc.h(qc.qubits)  # Apply Hadamard to create superposition\n",
    "\n",
    "feature_map = ZZFeatureMap(\n",
    "        feature_dimension=num_features,\n",
    "        entanglement='full'  # pattern of entanglement\n",
    "    )\n",
    "\n",
    "ansatz = EfficientSU2(num_qubits, reps=6)\n",
    "qc.compose(feature_map, inplace=True)\n",
    "qc.compose(ansatz, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsB1CiJyq9_6"
   },
   "outputs": [],
   "source": [
    "qc.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6iQ9t74tvW5"
   },
   "outputs": [],
   "source": [
    "# Sampler to evaluate the quantum circuit\n",
    "shots = 10000\n",
    "\n",
    "#new seed for each generator\n",
    "sampler=[]\n",
    "for i in range (n_device):\n",
    "    sampler.append(Sampler(options={\"shots\": shots, \"seed\": algorithm_globals.random_seed + i}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXQsDGeItvW5"
   },
   "outputs": [],
   "source": [
    "from qiskit.circuit import ParameterVector, QuantumCircuit  # Import ParameterVector\n",
    "\n",
    "# Define the quantum generator using TorchConnector\n",
    "def create_generator(i) -> TorchConnector:\n",
    "\n",
    "    # Specify the input_params to match the noise dimension\n",
    "    input_params = ParameterVector(\"input_params\", num_features)\n",
    "\n",
    "    # Modify the circuit to include input_params\n",
    "    qc_with_input = qc.copy()\n",
    "    for j in range(num_features):\n",
    "        qc_with_input.rx(input_params[j], j)  # Example: Apply rotation based on input_params\n",
    "\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc_with_input,  # Use the modified circuit\n",
    "        sampler=sampler[i],\n",
    "        input_params=input_params,\n",
    "        weight_params=qc_with_input.parameters[num_features:], # weight params are all params except input_params\n",
    "        sparse=False,\n",
    "        output_shape=num_features\n",
    "    )\n",
    "    initial_weights = algorithm_globals.random.random(qc_with_input.num_parameters - num_features) # initial weights are for weight params only\n",
    "    return TorchConnector(qnn, initial_weights)\n",
    "   \n",
    "\n",
    "#generator = create_generator()\n",
    "# Create generators and discriminators for three QGAN instances\n",
    "generators = [create_generator(i) for i in range(n_device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-WutxsetvW5"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Create a discriminator\n",
    "#discriminator = Discriminator(input_size=num_features)\n",
    "discriminators = [Discriminator(input_size=num_features) for _ in range(n_device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "lrd = 0.0006  # learning rate\n",
    "lrg = 0.001  # learning rate\n",
    "b1 = 0.7  # first momentum parameter\n",
    "b2 = 0.999  # second momentum parameter\n",
    "\n",
    "optimizers_g = [Adam(generator.parameters(), lr=lrg, betas=(b1, b2), weight_decay=0.005) for generator in generators]\n",
    "optimizers_d = [Adam(discriminator.parameters(), lr=lrd, betas=(b1, b2), weight_decay=0.005) for discriminator in discriminators]\n",
    "\n",
    "# Binary Cross-Entropy loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Label smoothing\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions_federated(real_data_federated, generated_data_federated, feature_names, instance_idx=None):\n",
    "    \"\"\"\n",
    "    Compare distributions of real and generated data for a federated setup.\n",
    "\n",
    "    Args:\n",
    "    - real_data: numpy array of real benign data\n",
    "    - generated_data_federated: list of numpy arrays, each representing generated data from a QGAN instance\n",
    "    - feature_names: list of feature names for labeling\n",
    "    - instance_idx: index of the specific QGAN instance to compare, or None for the averaged model\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    real_data_federated = real_data_federated.numpy() if torch.is_tensor(real_data_federated) else real_data_federated\n",
    "\n",
    "    #print(real_data_federated.shape)\n",
    "    #print(generated_data_federated.shape)\n",
    "\n",
    "    if instance_idx is None:  # Average generated data from all instances\n",
    "        generated_data = sum(generated_data_federated) / len(generated_data_federated)\n",
    "        title = \"Federated (Averaged) Generated Data\"\n",
    "    else:\n",
    "        generated_data = generated_data_federated[instance_idx]\n",
    "        title = f\"Generated Data: Instance {instance_idx + 1}\"\n",
    "\n",
    "    if instance_idx is None:  # Average generated data from all instances\n",
    "        real_data = sum(real_data_federated) / len(real_data_federated)\n",
    "        title1 = \"Federated (Averaged) Real Data\"\n",
    "    else:\n",
    "        real_data = real_data_federated[instance_idx]\n",
    "        title1 = f\"Real Data: Instance {instance_idx + 1}\"\n",
    "\n",
    "    # Create plots\n",
    "    fig, axes = plt.subplots(1, ncomp, figsize=(20, 4))\n",
    "    fig.suptitle(f'Data Distribution: {title1} vs {title}', fontsize=16)\n",
    "\n",
    "    for i in range(ncomp):\n",
    "        sns.histplot(real_data[:, i], kde=True, color='blue', alpha=0.5, ax=axes[i], label='Real Data')\n",
    "        sns.histplot(generated_data[:, i], kde=True, color='red', alpha=0.5, ax=axes[i], label='Generated Data')\n",
    "        axes[i].set_title(feature_names[i])\n",
    "        axes[i].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "feature_names = ['Principal Component 1','Principal Component 2','Principal Component 3','Principal Component 4','Principal Component 5','Principal Component 6']\n",
    "\n",
    "\n",
    "\n",
    "def compare_statistical_properties_federated(real_data, generated_data_federated):\n",
    "    \"\"\"\n",
    "    Compare statistical properties of real and generated data for a federated setup.\n",
    "\n",
    "    Args:\n",
    "    - real_data: numpy array of real benign data\n",
    "    - generated_data_federated: list of numpy arrays, each representing generated data from a QGAN instance\n",
    "    \"\"\"\n",
    "    real_data = real_data.numpy() if torch.is_tensor(real_data) else real_data\n",
    "\n",
    "    # Compute average generated data from all instances\n",
    "    generated_data_avg = sum(generated_data_federated) / len(generated_data_federated)\n",
    "    real_data = sum(real_data) / len(real_data)\n",
    "\n",
    "    print(\"\\nStatistical Comparisons (Federated):\")\n",
    "    print(\"\\nMean:\")\n",
    "    print(\"Real:      \", np.mean(real_data, axis=0))\n",
    "    print(\"Generated (Averaged):   \", np.mean(generated_data_avg, axis=0))\n",
    "\n",
    "    print(\"\\nStandard Deviation:\")\n",
    "    print(\"Real:      \", np.std(real_data, axis=0))\n",
    "    print(\"Generated (Averaged):   \", np.std(generated_data_avg, axis=0))\n",
    "\n",
    "    from scipy.stats import wasserstein_distance\n",
    "    print(\"\\nWasserstein Distance for Each Feature:\")\n",
    "    for i in range(real_data.shape[1]):\n",
    "        dist = wasserstein_distance(real_data[:, i], generated_data_avg[:, i])\n",
    "        print(f\"Feature {i}: {dist}\")\n",
    "\n",
    "    # Optionally compare individual instances\n",
    "    for idx, generated_data in enumerate(generated_data_federated):\n",
    "        print(f\"\\n--- Instance {idx + 1} ---\")\n",
    "        print(\"Mean: \", np.mean(generated_data, axis=0))\n",
    "        print(\"Std Dev: \", np.std(generated_data, axis=0))\n",
    "        for i in range(real_data.shape[1]):\n",
    "            dist = wasserstein_distance(real_data[:, i], generated_data[:, i])\n",
    "            print(f\"Feature {i}: Wasserstein Distance = {dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cp1h-7Ouq9_6"
   },
   "outputs": [],
   "source": [
    "# Lists to store losses for plotting (one per QGAN instance)\n",
    "generator_loss_values_federated = [[] for _ in range(n_device)]\n",
    "discriminator_loss_values_real_federated = [[] for _ in range(n_device)]\n",
    "discriminator_loss_values_fake_federated = [[] for _ in range(n_device)]\n",
    "\n",
    "title = \"Federated QGAN Training Progress\"\n",
    "\n",
    "def plot_training_progress_federated():\n",
    "    # Check if we have enough data for plotting\n",
    "    #print(len(generator_loss_values_federated))\n",
    "    #print(len(generator_loss_values_federated[0]))\n",
    "    if any(len(losses) < 2 for losses in generator_loss_values_federated):\n",
    "        print(\"NO\")\n",
    "        return\n",
    "\n",
    "    # Compute average losses across all instances for plotting\n",
    "    avg_generator_loss = [\n",
    "        sum(generator_loss_values_federated[i][epoch] for i in range(n_device)) / n_device\n",
    "        for epoch in range(len(generator_loss_values_federated[0]))\n",
    "    ]\n",
    "    avg_discriminator_loss_real = [\n",
    "        sum(discriminator_loss_values_real_federated[i][epoch] for i in range(n_device)) / n_device\n",
    "        for epoch in range(len(discriminator_loss_values_real_federated[0]))\n",
    "    ]\n",
    "    avg_discriminator_loss_fake = [\n",
    "        sum(discriminator_loss_values_fake_federated[i][epoch] for i in range(n_device)) / n_device\n",
    "        for epoch in range(len(discriminator_loss_values_fake_federated[0]))\n",
    "    ]\n",
    "\n",
    "    # Plot the average losses\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "    ax1.set_title(title)\n",
    "    ax1.plot([x for x in avg_generator_loss], label=\"Generator Loss (Avg)\", color=\"royalblue\")\n",
    "    ax1.plot([x for x in avg_discriminator_loss_real], label=\"Discriminator Loss Real (Avg)\", color=\"green\")\n",
    "    ax1.plot([x for x in avg_discriminator_loss_fake], label=\"Discriminator Loss Fake (Avg)\", color=\"red\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(title + '.png')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define thresholds to test\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "def evaluate_with_threshold_federated(threshold, benign_tensor, outlier_tensor, local_discriminators):\n",
    "    \"\"\"\n",
    "    Evaluate models at a given threshold for a federated setup.\n",
    "    \n",
    "    Args:\n",
    "    - threshold: Threshold to classify predictions.\n",
    "    - benign_tensor: Tensor of benign data samples.\n",
    "    - outlier_tensor: Tensor of outlier data samples.\n",
    "    - local_discriminators: List of local discriminator models.\n",
    "    \n",
    "    Returns:\n",
    "    - Federated overall metrics and per-model metrics.\n",
    "    \"\"\"\n",
    "    # Store metrics for each local model\n",
    "    metrics_per_model = []\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i, discriminator in enumerate(local_discriminators):\n",
    "        # Get predictions for benign and outlier\n",
    "        benign_predictions = discriminator(benign_tensor).detach()\n",
    "        outlier_predictions = discriminator(outlier_tensor).detach()\n",
    "\n",
    "        # Binary classifications using the threshold\n",
    "        benign_predictions_binary = (benign_predictions > threshold).float()\n",
    "        outlier_predictions_binary = (outlier_predictions > threshold).float()\n",
    "\n",
    "        # Labels\n",
    "        benign_labels = torch.ones(benign_tensor.shape[0])\n",
    "        outlier_labels = torch.zeros(outlier_tensor.shape[0])\n",
    "\n",
    "        # Compute metrics for this model\n",
    "        benign_accuracy = accuracy_score(benign_labels, benign_predictions_binary)\n",
    "        outlier_accuracy = accuracy_score(outlier_labels, outlier_predictions_binary)\n",
    "        all_model_predictions = torch.cat((benign_predictions_binary, outlier_predictions_binary))\n",
    "        all_model_labels = torch.cat((benign_labels, outlier_labels))\n",
    "\n",
    "        overall_accuracy = accuracy_score(all_model_labels, all_model_predictions)\n",
    "        precision = precision_score(all_model_labels, all_model_predictions, zero_division=0)\n",
    "        recall = recall_score(all_model_labels, all_model_predictions)\n",
    "        f1 = f1_score(all_model_labels, all_model_predictions)\n",
    "\n",
    "        metrics_per_model.append((overall_accuracy, benign_accuracy, outlier_accuracy, precision, recall, f1))\n",
    "\n",
    "        # Append predictions and labels for federated aggregation\n",
    "        all_predictions.append(all_model_predictions)\n",
    "        all_labels.append(all_model_labels)\n",
    "\n",
    "    # Federated evaluation: aggregate predictions from all models\n",
    "    #combined_predictions = torch.cat(all_predictions).mean(dim=0) > threshold\n",
    "    combined_predictions = torch.cat(all_predictions)\n",
    "    combined_labels = torch.cat(all_labels)\n",
    "    \n",
    "    #print(combined_labels)\n",
    "    #print(combined_predictions)\n",
    "    federated_overall_accuracy = accuracy_score(combined_labels, combined_predictions)\n",
    "    federated_precision = precision_score(combined_labels, combined_predictions,zero_division=0)\n",
    "    federated_recall = recall_score(combined_labels, combined_predictions)\n",
    "    federated_f1 = f1_score(combined_labels, combined_predictions)\n",
    "\n",
    "    return federated_overall_accuracy, federated_precision, federated_recall, federated_f1, metrics_per_model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert benign_data into a torch tensor\n",
    "benign_data_tensor = torch.tensor(benign_data, dtype=torch.float32)\n",
    "\n",
    "\n",
    "from multiprocessing import Process, Manager\n",
    "from copy import deepcopy\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 80\n",
    "batch_size = 64\n",
    "num_elements = 2 ** num_features\n",
    "\n",
    "# Separate datasets for federated training\n",
    "datasets = [\n",
    "    (\n",
    "        benign_data_tensor[i * len(benign_data_tensor) // n_device : (i + 1) * len(benign_data_tensor) // n_device],\n",
    "        outlier_tensor[i * len(outlier_tensor) // n_device : (i + 1) * len(outlier_tensor) // n_device]\n",
    "    )\n",
    "    for i in range(n_device)\n",
    "]\n",
    "split_data = np.array_split(benign_data_tensor, n_device)\n",
    "\n",
    "def train_qgan(index, datasets, generators, discriminators, optimizers_g, optimizers_d, results, num_features, num_elements, batch_size, num_epochs, criterion, real_label, fake_label):\n",
    "    benign_data, outlier_data = datasets[index]\n",
    "    generator = generators[index]\n",
    "    discriminator = discriminators[index]\n",
    "    optimizer_g = optimizers_g[index]\n",
    "    optimizer_d = optimizers_d[index]\n",
    "\n",
    "\n",
    "    for j in range(0, len(benign_data), batch_size):\n",
    "        real_data = benign_data[j:j + batch_size]\n",
    "        batch_size_real = real_data.size(0)\n",
    "        label_real = torch.full((batch_size_real,), real_label, dtype=torch.float32)\n",
    "\n",
    "        # Discriminator training on real data\n",
    "        optimizer_d.zero_grad()\n",
    "        output_real = discriminator(real_data).view(-1)\n",
    "        loss_real = criterion(output_real, label_real)\n",
    "        loss_real.backward()\n",
    "\n",
    "        # Fake data generation\n",
    "        noise = torch.randn(batch_size_real, num_features)\n",
    "        fake_data = generator(noise).detach()\n",
    "        transformed_data = torch.zeros((batch_size_real, num_features))\n",
    "\n",
    "        for i in range(num_features):\n",
    "            for row in range(batch_size_real):\n",
    "                sum_value = 0\n",
    "                for start in range(0, num_elements, 2**(i + 1)):\n",
    "                    sum_value += fake_data[row, start:start + 2**(i)].sum()\n",
    "                transformed_data[row, i] = sum_value\n",
    "        fake_data = transformed_data\n",
    "\n",
    "        label_fake = torch.full((batch_size_real,), fake_label, dtype=torch.float32)\n",
    "        output_fake = discriminator(fake_data).view(-1)\n",
    "        loss_fake = criterion(output_fake, label_fake)\n",
    "        loss_fake.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Generator training\n",
    "        optimizer_g.zero_grad()\n",
    "        fake_data = generator(noise)\n",
    "\n",
    "        for i in range(num_features):\n",
    "            for row in range(batch_size_real):\n",
    "                sum_value = 0\n",
    "                for start in range(0, num_elements, 2**(i + 1)):\n",
    "                    sum_value += fake_data[row, start:start + 2**(i)].sum()\n",
    "                transformed_data[row, i] = sum_value\n",
    "        fake_data = transformed_data\n",
    "\n",
    "        label_gen = torch.full((batch_size_real,), real_label, dtype=torch.float32)\n",
    "        output_gen = discriminator(fake_data).view(-1)\n",
    "        loss_gen = criterion(output_gen, label_gen)\n",
    "        loss_gen.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        #print(loss_gen)\n",
    "        #generator_loss_values_federated[index].append(loss_gen.item())\n",
    "        #discriminator_loss_values_real_federated[index].append(loss_real.item())\n",
    "        #discriminator_loss_values_fake_federated[index].append(loss_fake.item())\n",
    "    generator_loss_values=loss_gen.item()\n",
    "    discriminator_loss_values_real=loss_real.item()\n",
    "    discriminator_loss_values_fake=loss_fake.item()\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generate noise for this instance\n",
    "        noise = torch.randn(test_size, num_features)\n",
    "    \n",
    "        # Generate samples using the generator of this instance\n",
    "        generated_samples = generator(noise).detach()\n",
    "\n",
    "        # Transform the generated data\n",
    "        transformed_data = torch.zeros((test_size, num_features))\n",
    "        for i in range(num_features):\n",
    "            for row in range(test_size):\n",
    "                sum_value = 0\n",
    "                for start in range(0, num_elements,  2**(i + 1)): \n",
    "                    sum_value += generated_samples[row, start:start + 2**(i)].sum()\n",
    "                transformed_data[row, i] = sum_value\n",
    "\n",
    "        # Convert to numpy and store in the list\n",
    "        generated_data=transformed_data.numpy()\n",
    "\n",
    "    results[index] = {\n",
    "        \"generator\": deepcopy(generator.state_dict()),\n",
    "        \"discriminator\": deepcopy(discriminator.state_dict()),\n",
    "        \"generated\": generated_data,\n",
    "        \"lossg\": generator_loss_values,\n",
    "        \"lossr\": discriminator_loss_values_real,\n",
    "        \"lossf\": discriminator_loss_values_fake,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "manager = Manager()\n",
    "results = manager.dict()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    processes = []\n",
    "    for i in range(len(datasets)): #n_device\n",
    "        process = Process(\n",
    "            target=train_qgan,\n",
    "            args=(i, datasets, generators, discriminators, optimizers_g, optimizers_d, results, num_features, num_elements, batch_size, num_epochs, criterion, real_label, fake_label)\n",
    "        )\n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "    generated_data_federated=[]\n",
    "    for i in range(n_device):\n",
    "        generated_data_federated.append(results[i][\"generated\"]) \n",
    "        generator_loss_values_federated[i].append(results[i][\"lossg\"])\n",
    "        discriminator_loss_values_real_federated[i].append(results[i][\"lossr\"])\n",
    "        discriminator_loss_values_fake_federated[i].append(results[i][\"lossf\"])\n",
    "\n",
    "    compare_distributions_federated(split_data, generated_data_federated, feature_names)\n",
    "    #compare_statistical_properties_federated(split_data, generated_data_federated)\n",
    "    plot_training_progress_federated()\n",
    "\n",
    "    # Execution loop for thresholds\n",
    "    for threshold in thresholds:\n",
    "        federated_overall_accuracy, federated_precision, federated_recall, federated_f1, metrics_per_model = evaluate_with_threshold_federated(\n",
    "            threshold, benign_tensor, outlier_tensor, discriminators\n",
    "        )\n",
    "\n",
    "        print(f\"Threshold: {threshold:.1f} | Federated Accuracy: {federated_overall_accuracy:.4f} | Precision: {federated_precision:.4f} | Recall: {federated_recall:.4f} | F1 Score: {federated_f1:.4f}\")\n",
    "\n",
    "        # Print per-model metrics\n",
    "        for model_idx, (overall, benign_acc, outlier_acc, precision, recall, f1) in enumerate(metrics_per_model):\n",
    "            print(f\"  Model {model_idx + 1}: Overall Accuracy: {overall:.4f} | Benign Accuracy: {benign_acc:.4f} | Outlier Accuracy: {outlier_acc:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1 Score: {f1:.4f}\")\n",
    "    \n",
    "\n",
    "    avg_loss_gen = sum([generator_loss_values_federated[i][epoch] for i in range(n_device)]) / n_device\n",
    "    avg_loss_real = sum([discriminator_loss_values_real_federated[i][epoch] for i in range(n_device)]) / n_device\n",
    "    avg_loss_fake = sum([discriminator_loss_values_fake_federated[i][epoch] for i in range(n_device)]) / n_device\n",
    "\n",
    "    # Print the averaged losses for the current epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Avg Last Loss D real: {avg_loss_real:.4f}, Avg Last Loss D fake: {avg_loss_fake:.4f}, Avg Last Loss G: {avg_loss_gen:.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        avg_generator_weights = {\n",
    "            k: sum(results[i][\"generator\"][k] for i in range(len(datasets))) / len(datasets) for k in results[0][\"generator\"]\n",
    "        }\n",
    "        avg_discriminator_weights = {\n",
    "            k: sum(results[i][\"discriminator\"][k] for i in range(len(datasets))) / len(datasets) for k in results[0][\"discriminator\"]\n",
    "        }\n",
    "\n",
    "        for generator, discriminator in zip(generators, discriminators):\n",
    "            generator.load_state_dict(avg_generator_weights)\n",
    "            discriminator.load_state_dict(avg_discriminator_weights)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#testare tutto con seed iniziale diverso e calcolare media e std dev\n",
    "score = evaluate_model(global_model)  # Valuta il modello federato\n",
    "results.append((run, seed_client, score))  # Salva il risultato\n",
    "mean_score = np.mean(df_results[\"Score\"])\n",
    "std_dev = np.std(df_results[\"Score\"])\n",
    "print(f\"Media: {mean_score:.4f}, Deviazione standard: {std_dev:.4f}\")\n",
    "\n",
    "#piu dati\n",
    "#verificare tutto il codice\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
